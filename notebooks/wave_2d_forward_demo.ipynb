{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Elastic Wave PINN with FDTD Data Integration\n",
    "\n",
    "このノートブックは、FDTDシミュレーションデータを用いた2D弾性波方程式PINNの完全なワークフローを示します。\n",
    "\n",
    "## 概要\n",
    "\n",
    "**2D Elastic Wave Equations (Dimensionless Form)**:\n",
    "- Longitudinal: $\\frac{\\partial^2 \\tilde{U}_x}{\\partial \\tilde{t}^2} = \\frac{\\partial^2 \\tilde{U}_x}{\\partial \\tilde{x}^2} + \\frac{\\partial^2 \\tilde{U}_x}{\\partial \\tilde{y}^2}$\n",
    "- Transverse: $\\frac{\\partial^2 \\tilde{U}_y}{\\partial \\tilde{t}^2} = (c_t/c_l)^2 \\left(\\frac{\\partial^2 \\tilde{U}_y}{\\partial \\tilde{x}^2} + \\frac{\\partial^2 \\tilde{U}_y}{\\partial \\tilde{y}^2}\\right)$\n",
    "\n",
    "where $(c_t/c_l)^2 \\approx 0.25$ for Aluminum 6061-T6.\n",
    "\n",
    "## ワークフロー\n",
    "\n",
    "1. FDTDデータの読み込みと無次元化\n",
    "2. Train/Validation分割\n",
    "3. 2D PINNモデルの構築（実装予定）\n",
    "4. 訓練の実行（実装予定）\n",
    "5. R²スコアによる検証\n",
    "6. 2D空間分布の可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## セットアップとインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.0+cu124\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "# PINN module imports\n",
    "from pinn.data.fdtd_loader import FDTDDataLoaderService\n",
    "from pinn.data.dimensionless_scaler import CharacteristicScales, DimensionlessScalerService\n",
    "from pinn.validation.r2_score import R2ScoreCalculator\n",
    "from pinn.utils.config_loader import ConfigLoaderService\n",
    "from pinn.utils.seed_manager import SeedManager\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 10)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: 設定ファイルの読み込み\n",
    "\n",
    "2D PINN用のYAML設定を読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: pinn_2d_parametric_elastic_wave\n",
      "\n",
      "Domain: x ∈ [0.0, 0.04], t ∈ [3.50e-06, 1.00e-05]\n",
      "\n",
      "Network: [5, 64, 64, 64, 4]\n",
      "Activation: tanh\n",
      "\n",
      "Training iterations: 20000\n",
      "Learning rate: 0.001\n",
      "Loss weights: {'pde': 1.0, 'data': 1.0}\n",
      "\n",
      "Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config_path = project_root / \"configs\" / \"pinn_2d_example.yaml\"\n",
    "config_loader = ConfigLoaderService()\n",
    "config = config_loader.load_config(config_path)\n",
    "\n",
    "# Also load raw YAML for fields not in pydantic model\n",
    "import yaml\n",
    "\n",
    "with open(config_path) as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "print(f\"Experiment: {config.experiment_name}\")\n",
    "print(\n",
    "    f\"\\nDomain: x ∈ [{config.domain.x_min}, {config.domain.x_max}], t ∈ [{config.domain.t_min:.2e}, {config.domain.t_max:.2e}]\"\n",
    ")\n",
    "print(f\"\\nNetwork: {config.network.layer_sizes}\")\n",
    "print(f\"Activation: {config.network.activation}\")\n",
    "print(f\"\\nTraining iterations: {config_dict['training']['iterations']}\")\n",
    "print(f\"Learning rate: {config.training.learning_rate}\")\n",
    "print(f\"Loss weights: {config.training.loss_weights}\")\n",
    "\n",
    "# Set random seed\n",
    "SeedManager.set_seed(config.seed)\n",
    "print(f\"\\nRandom seed: {config.seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: FDTDデータの読み込み\n",
    "\n",
    "FDTDシミュレーションデータを読み込み、無次元化を適用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Real FDTD data not found in /PINN_data\n",
      "    Creating synthetic data for demonstration...\n",
      "\n",
      "✓ Created synthetic data: /tmp/tmpj2aq5gqi/p1250_d100.npz\n",
      "  Shape: 80×40×60 = 192000 samples\n",
      "\n",
      "Found 1 FDTD data files:\n",
      "  - p1250_d100.npz\n"
     ]
    }
   ],
   "source": [
    "# Data directory (modify if needed)\n",
    "data_dir = Path(\"/home/manat/project2/PINN_data\")\n",
    "\n",
    "# Check if real data exists, otherwise use synthetic data\n",
    "if not data_dir.exists() or not list(data_dir.glob(\"p*_d*.npz\")):\n",
    "    print(\"⚠️  Real FDTD data not found in /PINN_data\")\n",
    "    print(\"    Creating synthetic data for demonstration...\\n\")\n",
    "\n",
    "    # Create temporary directory with synthetic data\n",
    "    import tempfile\n",
    "\n",
    "    data_dir = Path(tempfile.mkdtemp())\n",
    "\n",
    "    # Generate synthetic FDTD file\n",
    "    np.random.seed(42)\n",
    "    nx, ny, nt = 80, 40, 60\n",
    "    n_total = nx * ny * nt\n",
    "\n",
    "    x_grid = np.linspace(0, 0.04, nx)\n",
    "    y_grid = np.linspace(0, 0.02, ny)\n",
    "    t_grid = np.linspace(3.5e-6, 6.5e-6, nt)\n",
    "\n",
    "    X, Y, T = np.meshgrid(x_grid, y_grid, t_grid, indexing=\"ij\")\n",
    "\n",
    "    synthetic_file = data_dir / \"p1250_d100.npz\"\n",
    "    np.savez(\n",
    "        synthetic_file,\n",
    "        x=X.flatten(),\n",
    "        y=Y.flatten(),\n",
    "        t=T.flatten(),\n",
    "        T1=np.random.randn(n_total) * 1e9,\n",
    "        T3=np.random.randn(n_total) * 1e9,\n",
    "        Ux=np.random.randn(n_total) * 1e-9,\n",
    "        Uy=np.random.randn(n_total) * 1e-9,\n",
    "        p=1.25e-3,\n",
    "        d=0.1e-3,\n",
    "        w=0.3e-3,\n",
    "        seed=42,\n",
    "        nx_sample=nx,\n",
    "        ny_sample=ny,\n",
    "        nt_sample=nt,\n",
    "    )\n",
    "\n",
    "    print(f\"✓ Created synthetic data: {synthetic_file}\")\n",
    "    print(f\"  Shape: {nx}×{ny}×{nt} = {n_total} samples\\n\")\n",
    "\n",
    "# Create FDTD data loader\n",
    "loader = FDTDDataLoaderService(data_dir=data_dir)\n",
    "\n",
    "# Get available .npz files\n",
    "npz_files = sorted(data_dir.glob(\"p*_d*.npz\"))\n",
    "print(f\"Found {len(npz_files)} FDTD data files:\")\n",
    "for f in npz_files:\n",
    "    print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: 無次元化スケーラーの作成\n",
    "\n",
    "物理定数から特性スケールを計算し、無次元化を適用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load elastic constants from config\n",
    "import yaml\n",
    "\n",
    "with open(config_path) as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "elastic_lambda = float(config_dict[\"domain\"][\"elastic_lambda\"])\n",
    "elastic_mu = float(config_dict[\"domain\"][\"elastic_mu\"])\n",
    "density = float(config_dict[\"domain\"][\"density\"])\n",
    "\n",
    "print(\"Elastic constants (Aluminum 6061-T6):\")\n",
    "print(f\"  λ = {elastic_lambda:.2e} Pa\")\n",
    "print(f\"  μ = {elastic_mu:.2e} Pa\")\n",
    "print(f\"  ρ = {density:.1f} kg/m³\")\n",
    "\n",
    "# Estimate U_ref from first file\n",
    "sample_data = loader.load_file(npz_files[0])\n",
    "U_ref = np.std(np.concatenate([sample_data.Ux, sample_data.Uy]))\n",
    "\n",
    "print(f\"\\nEstimated U_ref: {U_ref:.2e} m\")\n",
    "\n",
    "# Create characteristic scales\n",
    "scales = CharacteristicScales.from_physics(\n",
    "    domain_length=config.domain.x_max,\n",
    "    elastic_lambda=elastic_lambda,\n",
    "    elastic_mu=elastic_mu,\n",
    "    density=density,\n",
    "    displacement_amplitude=U_ref,\n",
    ")\n",
    "\n",
    "# Create scaler\n",
    "scaler = DimensionlessScalerService(scales)\n",
    "\n",
    "print(f\"\\nCharacteristic scales:\")\n",
    "print(f\"  L_ref = {scales.L_ref:.4f} m\")\n",
    "print(f\"  T_ref = {scales.T_ref:.2e} s\")\n",
    "print(f\"  U_ref = {scales.U_ref:.2e} m\")\n",
    "print(f\"  σ_ref = {scales.sigma_ref:.2e} Pa\")\n",
    "print(f\"  c_l   = {scales.velocity_ref:.0f} m/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: データのロードと正規化\n",
    "\n",
    "複数のFDTDファイルを読み込み、無次元化を適用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and normalize data\n",
    "dataset = loader.load_multiple_files(npz_files, apply_dimensionless=True, scaler=scaler)\n",
    "\n",
    "print(f\"✓ Loaded {len(dataset.x)} samples from {len(npz_files)} file(s)\")\n",
    "print(f\"\\nData ranges (dimensionless):\")\n",
    "print(f\"  x:  [{np.min(dataset.x):.3f}, {np.max(dataset.x):.3f}]\")\n",
    "print(f\"  y:  [{np.min(dataset.y):.3f}, {np.max(dataset.y):.3f}]\")\n",
    "print(f\"  t:  [{np.min(dataset.t):.3f}, {np.max(dataset.t):.3f}]\")\n",
    "print(f\"  T1: [{np.min(dataset.T1):.3f}, {np.max(dataset.T1):.3f}]\")\n",
    "print(f\"  T3: [{np.min(dataset.T3):.3f}, {np.max(dataset.T3):.3f}]\")\n",
    "print(f\"  Ux: [{np.min(dataset.Ux):.3f}, {np.max(dataset.Ux):.3f}]\")\n",
    "print(f\"  Uy: [{np.min(dataset.Uy):.3f}, {np.max(dataset.Uy):.3f}]\")\n",
    "print(f\"\\nParameter ranges (normalized [0,1]):\")\n",
    "print(f\"  pitch_norm: [{np.min(dataset.pitch_norm):.3f}, {np.max(dataset.pitch_norm):.3f}]\")\n",
    "print(f\"  depth_norm: [{np.min(dataset.depth_norm):.3f}, {np.max(dataset.depth_norm):.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train/Validation分割\n",
    "\n",
    "データを訓練用と検証用に分割します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/val split\n",
    "train_ratio = config_dict[\"training\"].get(\"train_ratio\", 0.8)\n",
    "validation_equals_train = config_dict[\"training\"].get(\"validation_equals_train\", False)\n",
    "\n",
    "train_data, val_data = loader.train_val_split(\n",
    "    dataset, train_ratio=train_ratio, seed=config.seed, validation_equals_train=validation_equals_train\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_data.x)}\")\n",
    "print(f\"Val samples: {len(val_data.x)}\")\n",
    "if validation_equals_train:\n",
    "    print(\"Note: Validation = Training (for overfitting monitoring)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: R²スコアの計算（合成予測で検証）\n",
    "\n",
    "R²スコア計算機能をテストします。実際のPINN訓練後は、ここでモデル予測と比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create R² score calculator\n",
    "calculator = R2ScoreCalculator()\n",
    "\n",
    "# For demonstration, create synthetic predictions\n",
    "# (In actual workflow, these would be PINN model predictions)\n",
    "n_samples_test = min(1000, len(val_data.x))\n",
    "\n",
    "y_true = {\n",
    "    \"T1\": val_data.T1[:n_samples_test],\n",
    "    \"T3\": val_data.T3[:n_samples_test],\n",
    "    \"Ux\": val_data.Ux[:n_samples_test],\n",
    "    \"Uy\": val_data.Uy[:n_samples_test],\n",
    "}\n",
    "\n",
    "# Synthetic predictions: add small noise to true values\n",
    "np.random.seed(config.seed)\n",
    "y_pred = {k: v + np.random.randn(len(v)) * 0.05 * np.std(v) for k, v in y_true.items()}\n",
    "\n",
    "# Compute R² scores\n",
    "r2_scores = calculator.compute_r2_multi_output(y_true, y_pred)\n",
    "\n",
    "print(\"R² Scores (Synthetic Predictions):\")\n",
    "print(\"=\" * 40)\n",
    "for field, r2 in r2_scores.items():\n",
    "    print(f\"  {field:4s}: {r2:.4f}\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Format report\n",
    "report = calculator.format_report(r2_scores, threshold=0.9)\n",
    "print(\"\\n\" + report)\n",
    "\n",
    "print(\"\\nNote: After PINN training, replace synthetic predictions with actual model outputs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: 2D空間分布の可視化\n",
    "\n",
    "特定の時刻における2D波動場を可視化します（FDTDデータ）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 3 time snapshots for visualization\n",
    "t_unique = np.unique(dataset.t)\n",
    "t_indices = [len(t_unique) // 4, len(t_unique) // 2, 3 * len(t_unique) // 4]\n",
    "t_snapshots = [t_unique[i] for i in t_indices]\n",
    "\n",
    "print(f\"Time snapshots (dimensionless): {[f'{t:.3f}' for t in t_snapshots]}\")\n",
    "\n",
    "# Get unique x, y grids\n",
    "x_unique = np.unique(dataset.x)\n",
    "y_unique = np.unique(dataset.y)\n",
    "\n",
    "print(f\"Spatial grid: {len(x_unique)}×{len(y_unique)}\")\n",
    "\n",
    "# Visualize Ux field at 3 time snapshots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for i, (ax, t_val) in enumerate(zip(axes, t_snapshots)):\n",
    "    # Find data at this time\n",
    "    mask = np.abs(dataset.t - t_val) < 1e-6\n",
    "\n",
    "    if np.sum(mask) > 0:\n",
    "        x_plot = dataset.x[mask]\n",
    "        y_plot = dataset.y[mask]\n",
    "        ux_plot = dataset.Ux[mask]\n",
    "\n",
    "        # Reshape to 2D grid if possible\n",
    "        if len(x_plot) == len(x_unique) * len(y_unique):\n",
    "            X = x_plot.reshape(len(x_unique), len(y_unique))\n",
    "            Y = y_plot.reshape(len(x_unique), len(y_unique))\n",
    "            Ux_grid = ux_plot.reshape(len(x_unique), len(y_unique))\n",
    "\n",
    "            # Plot using pcolormesh\n",
    "            im = ax.pcolormesh(X, Y, Ux_grid, cmap=\"RdBu_r\", shading=\"auto\")\n",
    "            ax.set_xlabel(\"x (dimensionless)\", fontsize=10)\n",
    "            ax.set_ylabel(\"y (dimensionless)\", fontsize=10)\n",
    "            ax.set_title(f\"t = {t_val:.3f}\", fontsize=12)\n",
    "            ax.set_aspect(\"equal\")\n",
    "            plt.colorbar(im, ax=ax, label=\"Ux\")\n",
    "        else:\n",
    "            # Scatter plot if grid structure is unclear\n",
    "            scatter = ax.scatter(x_plot, y_plot, c=ux_plot, cmap=\"RdBu_r\", s=1)\n",
    "            ax.set_xlabel(\"x\", fontsize=10)\n",
    "            ax.set_ylabel(\"y\", fontsize=10)\n",
    "            ax.set_title(f\"t = {t_val:.3f}\", fontsize=12)\n",
    "            plt.colorbar(scatter, ax=ax, label=\"Ux\")\n",
    "\n",
    "plt.suptitle(\"FDTD Data: Ux Field at Different Times\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "このノートブックでは以下を実装しました：\n",
    "\n",
    "1. ✓ FDTDデータの読み込みと無次元化\n",
    "2. ✓ Train/Validation分割\n",
    "3. ✓ R²スコア計算機能のテスト\n",
    "4. ✓ 2D波動場の可視化（基本プロット）\n",
    "5. ✓ plot_time_snapshots可視化（Task 4.3）\n",
    "6. ✓ plot_spatial_heatmap誤差分布可視化（Task 4.4）\n",
    "\n",
    "## 今後の拡張（実装予定）\n",
    "\n",
    "- 2D PINNモデルの構築と訓練（PINNModelBuilder2DService使用）\n",
    "- 実際のPINN訓練ループとR²モニタリングコールバック\n",
    "- パラメトリック予測（異なるpitch/depthでの評価）\n",
    "- 損失重み調整と収束性の改善\n",
    "\n",
    "**Note**: 本ノートブックは現在、合成予測データを使用してR²計算および可視化機能を実証しています。  \n",
    "完全なPINN訓練パイプライン実装後は、実際のPINN予測との比較が可能になります。\n",
    "\n",
    "## 参考\n",
    "\n",
    "- Design: `.kiro/specs/pinn-2d-fdtd-integration/design.md`\n",
    "- Requirements: `.kiro/specs/pinn-2d-fdtd-integration/requirements.md`\n",
    "- Loss Weight Validation: `docs/loss_weight_validation.md`\n",
    "- Implementation: Tasks 4.2-4.4 (R² monitoring, visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PlotGeneratorService\n",
    "from pinn.validation.plot_generator import PlotGeneratorService\n",
    "\n",
    "# Create plot generator\n",
    "plot_gen = PlotGeneratorService()\n",
    "\n",
    "# Prepare data for plot_time_snapshots (requires physical units in meters)\n",
    "# First, denormalize data back to physical units\n",
    "x_physical = dataset.x * scales.L_ref\n",
    "y_physical = dataset.y * scales.L_ref\n",
    "t_physical = dataset.t * scales.T_ref\n",
    "\n",
    "# Get unique grids\n",
    "x_unique_phys = np.unique(x_physical)\n",
    "y_unique_phys = np.unique(y_physical)\n",
    "t_unique_phys = np.unique(t_physical)\n",
    "\n",
    "# Select 3 time snapshots\n",
    "t_snap_indices = [len(t_unique_phys) // 4, len(t_unique_phys) // 2, 3 * len(t_unique_phys) // 4]\n",
    "t_snap_list = [t_unique_phys[i] for i in t_snap_indices]\n",
    "\n",
    "print(f\"Selected time snapshots (physical): {[f'{t * 1e6:.2f} µs' for t in t_snap_list]}\")\n",
    "\n",
    "# Prepare FDTD and \"PINN\" data dictionaries\n",
    "fdtd_data = {}\n",
    "pinn_pred = {}\n",
    "\n",
    "for t_val in t_snap_list:\n",
    "    # Find data at this time\n",
    "    mask = np.abs(t_physical - t_val) < 1e-9\n",
    "\n",
    "    if np.sum(mask) > 0:\n",
    "        x_at_t = x_physical[mask]\n",
    "        y_at_t = y_physical[mask]\n",
    "        ux_at_t = dataset.Ux[mask] * scales.U_ref  # Denormalize to physical units\n",
    "\n",
    "        # Reshape to 2D grid\n",
    "        if len(x_at_t) == len(x_unique_phys) * len(y_unique_phys):\n",
    "            Ux_grid = ux_at_t.reshape(len(y_unique_phys), len(x_unique_phys))\n",
    "            fdtd_data[t_val] = Ux_grid\n",
    "\n",
    "            # Synthetic PINN prediction (add small noise for demo)\n",
    "            pinn_pred[t_val] = Ux_grid + np.random.randn(*Ux_grid.shape) * 0.05 * np.std(Ux_grid)\n",
    "\n",
    "# Generate plot\n",
    "if len(fdtd_data) >= 3:\n",
    "    fig, axes = plot_gen.plot_time_snapshots(\n",
    "        x=x_unique_phys, y=y_unique_phys, t_list=t_snap_list, fdtd_data=fdtd_data, pinn_pred=pinn_pred, output_field=\"Ux\"\n",
    "    )\n",
    "    plt.show()\n",
    "    print(\"\\n✓ plot_time_snapshots visualization complete\")\n",
    "else:\n",
    "    print(\"⚠️  Not enough time snapshots for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: plot_spatial_heatmap可視化（Task 4.4）\n",
    "\n",
    "誤差分布ヒートマップを生成し、空間領域全体でのPINN予測精度を評価します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate spatial error distribution for middle time snapshot\n",
    "t_mid = t_snap_list[1]\n",
    "\n",
    "if t_mid in fdtd_data and t_mid in pinn_pred:\n",
    "    # Compute absolute error\n",
    "    error_map = np.abs(pinn_pred[t_mid] - fdtd_data[t_mid])\n",
    "\n",
    "    # Generate heatmap\n",
    "    fig, ax = plot_gen.plot_spatial_heatmap(x=x_unique_phys, y=y_unique_phys, error=error_map, output_field=\"Ux\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\n✓ Spatial heatmap visualization complete\")\n",
    "    print(f\"Error statistics:\")\n",
    "    print(f\"  Mean error: {np.mean(error_map):.2e} m\")\n",
    "    print(f\"  Max error: {np.max(error_map):.2e} m\")\n",
    "    print(f\"  Relative error: {np.mean(error_map) / np.std(fdtd_data[t_mid]) * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"⚠️  Data not available for heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "このノートブックでは以下を実装しました：\n",
    "\n",
    "1. ✓ FDTDデータの読み込みと無次元化\n",
    "2. ✓ Train/Validation分割\n",
    "3. ✓ R²スコア計算機能のテスト\n",
    "4. ✓ 2D波動場の可視化\n",
    "\n",
    "## 今後の拡張\n",
    "\n",
    "- 2D PINNモデルの構築と訓練（PINNModelBuilder2DService使用）\n",
    "- PINN予測とFDTDデータの比較プロット\n",
    "- パラメトリック予測（異なるpitch/depthでの評価）\n",
    "- 損失重み調整と収束性の改善\n",
    "\n",
    "## 参考\n",
    "\n",
    "- Design: `.kiro/specs/pinn-2d-fdtd-integration/design.md`\n",
    "- Requirements: `.kiro/specs/pinn-2d-fdtd-integration/requirements.md`\n",
    "- Loss Weight Validation: `docs/loss_weight_validation.md`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
